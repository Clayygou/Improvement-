## 问题
有哪些文本表示模型？ 它们各有什么优缺点？
## 分析
文本是一类非常重要的非结构化数据， 如何表示文本数据一直是机器学习领域的一个重要研究方向。
### 词袋模型（Bag of Words）和N-gram模型
#### 词袋模型
词袋模型， 顾名思义， 就是将每篇文章看成一袋子词， 并忽略每个词出现的顺序。 具体地说， 就是将整段文本以词为单位切分开，然后每篇文章可以表示成一个长向量， 向量中的每一维代表一个单词， 而该维对应的权重则反映了这个词在原文章中的重要程度。
常用TF-IDF来计算权重， 公式为：
![image](https://github.com/Clayygou/Improvement-/blob/master/%E5%9B%BE%E7%89%87/%E5%85%AC%E5%BC%8F1-5.1.jpg)
其中TF(t,d)为单词t在文档d中出现的频率， IDF(t)是逆文档频率， 用来衡量单词t对表达语义所起的重要性， 表示为:
![](https://github.com/Clayygou/Improvement-/blob/master/%E5%9B%BE%E7%89%87/%E5%85%AC%E5%BC%8F1-5.2.jpg)
最直观的理解就是如果一个单词在非常多的文章里面都出现， 那么它可能是一个比较通用的词汇， 对于区分某篇文章特殊语义的贡献较小， 因此对权重做一定惩罚,
（公式中加1是为了防止0的出现）。
#### N-gram模型
词袋模型忽略了文章中单词的排列顺序，所以，通常我们可以将连续出现的n个词（n≤N） 组成的词组（N-gram） 也作为一个单独的特征放到向量表示中去， 构成N-gram模型。
在实际应用中， 一般会对单词进行词干抽取（Word Stemming） 处理， 即将不同词性的单词统一成为同一词干的形式，也就是去除词缀得到词根的过程。
### 主题模型
主题模型用于从文本库中发现有代表性的主题（得到每个主题上面词的分布特性） ， 并且能够计算出每篇文章的主题分布。
### 词嵌入与深度学习模型
词嵌入是一类将词向量化的模型的统称， 核心思想是将每个词都映射成低维空间（通常K=50～300维） 上的一个稠密向量（Dense Vector） 。 K维空间的每一维也可以看作一个隐含的主题， 只不过不像主题模型中的主题那样直观。


由于词嵌入将每个词映射成一个K维的向量， 如果一篇文档有N个词， 就可以用一个N×K维的矩阵来表示这篇文档， 但是这样的表示过于底层。 在实际应用中， 如果仅仅把这个矩阵作为原文本的表示特征输入到机器学习模型中， 通常很难得到令人满意的结果。 因此， 还需要在此基础之上加工出更高层的特征。 在传统的浅层机器学习模型中， 一个好的特征工程往往可以带来算法效果的显著提升。 而深度学习模型正好为我们提供了一种自动地进行特征工程的方式， **模型中的每个隐层都可以认为对应着不同抽象层次的特征**。 从这个角度来讲， **深度学习模型能够打败浅层模型也就顺理成章了**。 卷积神经网络和循环神经网络的结构在文本表示中取得了很好的效果， 主要是由于它们能够更好地对文本进行建模， 抽取出一些高层的语义特征。 与全连接的网络结构相比， 卷积神经网络和循环神经网络一方面很好地抓住了文本的特性， 另一方面又减少了网络中待学习的参数，提高了训练速度， 并且降低了过拟合的风险。
